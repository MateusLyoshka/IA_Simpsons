{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951672c9",
   "metadata": {},
   "source": [
    "# Sistema Inteligente de Classificação de Personagens dos Simpsons\n",
    "\n",
    "Este notebook implementa um sistema completo de classificação de imagens para identificar personagens dos Simpsons, inspirado na estrutura do sistema de classificação de sementes de soja.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "- Extrair características de imagens usando descritores\n",
    "- Treinar e comparar classificadores (Random Forest, SVM, k-NN)\n",
    "- Avaliar desempenho com métricas e matriz de confusão\n",
    "\n",
    "**Alunos:** Alexandre Borges Baccarini Júnior, Leonardo, Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b174023",
   "metadata": {},
   "source": [
    "## 1. Instalação e Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0af410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instale as bibliotecas necessárias (execute apenas uma vez)\n",
    "%pip install numpy pandas scikit-learn scikit-image matplotlib seaborn Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de9968",
   "metadata": {},
   "source": [
    "## 2. Funções de Extração de Características (LBP, LPQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp(image: np.ndarray, P: int = 8, R: int = 2, method: str = 'nri_uniform'):\n",
    "    assert isinstance(image, np.ndarray) and len(image.shape) == 2\n",
    "    desc = local_binary_pattern(image, P, R, method=method)\n",
    "    n_bins = int(desc.max() + 1)\n",
    "    hist, _ = np.histogram(desc, density=True, bins=n_bins, range=(0, n_bins))\n",
    "    return hist\n",
    "\n",
    "def lpq(img, winSize=7, decorr=1, mode='nh'):\n",
    "    rho = 0.90\n",
    "    STFTalpha = 1/winSize\n",
    "    convmode = 'valid'\n",
    "    img = np.float64(img)\n",
    "    r = (winSize-1)/2\n",
    "    x = np.arange(-r, r+1)[np.newaxis]\n",
    "    w0 = np.ones_like(x)\n",
    "    w1 = np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "    w2 = np.conj(w1)\n",
    "    filterResp1 = convolve2d(convolve2d(img, w0.T, convmode), w1, convmode)\n",
    "    filterResp2 = convolve2d(convolve2d(img, w1.T, convmode), w0, convmode)\n",
    "    filterResp3 = convolve2d(convolve2d(img, w1.T, convmode), w1, convmode)\n",
    "    filterResp4 = convolve2d(convolve2d(img, w1.T, convmode), w2, convmode)\n",
    "    freqResp = np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                          filterResp2.real, filterResp2.imag,\n",
    "                          filterResp3.real, filterResp3.imag,\n",
    "                          filterResp4.real, filterResp4.imag])\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis, np.newaxis, :]\n",
    "    LPQdesc = ((freqResp > 0) * (2**inds)).sum(2)\n",
    "    if mode == 'nh' or mode == 'h':\n",
    "        LPQdesc = np.histogram(LPQdesc.flatten(), range(257))[0]\n",
    "    if mode == 'nh':\n",
    "        LPQdesc = LPQdesc / LPQdesc.sum()\n",
    "    return LPQdesc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbeb5f",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Extração de Características das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_directory(base_path, descriptor='lbp'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                img_path = os.path.join(class_dir, fname)\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    img = np.array(img)\n",
    "                    if descriptor == 'lbp':\n",
    "                        feat = lbp(img)\n",
    "                    elif descriptor == 'lpq':\n",
    "                        feat = lpq(img)\n",
    "                    else:\n",
    "                        raise ValueError(\"Descriptor inválido\")\n",
    "                    features.append(feat)\n",
    "                    labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao processar {img_path}: {e}\")\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251d7fb",
   "metadata": {},
   "source": [
    "## 4. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho para o dataset (ajuste conforme sua estrutura)\n",
    "base_path = \"./datasets\"  # Exemplo: \"./imgs/Train\" com subpastas para cada personagem\n",
    "\n",
    "# Extraia características LBP\n",
    "X, y = extract_features_from_directory(base_path, descriptor='lbp')\n",
    "print(f\"Total de amostras: {X.shape[0]}, Dimensão das features: {X.shape[1]}\")\n",
    "print(\"Classes:\", np.unique(y))\n",
    "\n",
    "# Codificar labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f552bef",
   "metadata": {},
   "source": [
    "## 5. Treinamento e Avaliação dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b444d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(clf, X_train, y_train, X_test, y_test, class_names):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia: {acc:.4f}\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusão\")\n",
    "    plt.show()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ae5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest:\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "train_and_evaluate_classifier(rf, X_train_scaled, y_train, X_test_scaled, y_test, le.classes_)\n",
    "\n",
    "# SVM\n",
    "print(\"SVM:\")\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "train_and_evaluate_classifier(svm, X_train_scaled, y_train, X_test_scaled, y_test, le.classes_)\n",
    "\n",
    "# k-NN\n",
    "print(\"k-NN:\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "train_and_evaluate_classifier(knn, X_train_scaled, y_train, X_test_scaled, y_test, le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e21107",
   "metadata": {},
   "source": [
    "## 6. Comparação entre LBP e LPQ\n",
    "\n",
    "Repita a extração e avaliação usando LPQ para comparar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3444de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração de características LPQ\n",
    "X_lpq, y_lpq = extract_features_from_directory(base_path, descriptor='lpq')\n",
    "y_lpq_encoded = le.transform(y_lpq)\n",
    "X_train_lpq, X_test_lpq, y_train_lpq, y_test_lpq = train_test_split(X_lpq, y_lpq_encoded, test_size=0.2, random_state=42, stratify=y_lpq_encoded)\n",
    "\n",
    "X_train_lpq_scaled = scaler.fit_transform(X_train_lpq)\n",
    "X_test_lpq_scaled = scaler.transform(X_test_lpq)\n",
    "\n",
    "print(\"Random Forest (LPQ):\")\n",
    "train_and_evaluate_classifier(RandomForestClassifier(n_estimators=100, random_state=42), X_train_lpq_scaled, y_train_lpq, X_test_lpq_scaled, y_test_lpq, le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651073e5",
   "metadata": {},
   "source": [
    "## 7. Otimização de Hiperparâmetros com GridSearchCV\n",
    "\n",
    "Vamos otimizar os principais classificadores usando GridSearchCV para ambos os descritores (LBP e LPQ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV para Random Forest, SVM e k-NN com LBP\n",
    "\n",
    "def grid_search_all(X_train, y_train, X_test, y_test, class_names):\n",
    "    results = {}\n",
    "    # Random Forest\n",
    "    rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "    rf_gs = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, n_jobs=-1)\n",
    "    rf_gs.fit(X_train, y_train)\n",
    "    print(\"Random Forest melhores parâmetros:\", rf_gs.best_params_)\n",
    "    acc_rf = train_and_evaluate_classifier(rf_gs.best_estimator_, X_train, y_train, X_test, y_test, class_names)\n",
    "    results['RandomForest'] = acc_rf\n",
    "\n",
    "    # SVM\n",
    "    svm_params = {'C': [0.1, 1, 10], 'gamma': ['scale', 0.01, 0.1]}\n",
    "    svm_gs = GridSearchCV(SVC(kernel='rbf', random_state=42), svm_params, cv=3, n_jobs=-1)\n",
    "    svm_gs.fit(X_train, y_train)\n",
    "    print(\"SVM melhores parâmetros:\", svm_gs.best_params_)\n",
    "    acc_svm = train_and_evaluate_classifier(svm_gs.best_estimator_, X_train, y_train, X_test, y_test, class_names)\n",
    "    results['SVM'] = acc_svm\n",
    "\n",
    "    # k-NN\n",
    "    knn_params = {'n_neighbors': [3, 5, 7]}\n",
    "    knn_gs = GridSearchCV(KNeighborsClassifier(), knn_params, cv=3, n_jobs=-1)\n",
    "    knn_gs.fit(X_train, y_train)\n",
    "    print(\"k-NN melhores parâmetros:\", knn_gs.best_params_)\n",
    "    acc_knn = train_and_evaluate_classifier(knn_gs.best_estimator_, X_train, y_train, X_test, y_test, class_names)\n",
    "    results['k-NN'] = acc_knn\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Otimização com LBP:\")\n",
    "results_lbp = grid_search_all(X_train_scaled, y_train, X_test_scaled, y_test, le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV para Random Forest, SVM e k-NN com LPQ\n",
    "\n",
    "print(\"Otimização com LPQ:\")\n",
    "results_lpq = grid_search_all(X_train_lpq_scaled, y_train_lpq, X_test_lpq_scaled, y_test_lpq, le.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

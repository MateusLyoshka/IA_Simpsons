{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final - Inteligência Computacional\n",
    "## Classificação de Personagens dos Simpsons\n",
    "\n",
    "**Objetivo:** Desenvolver e avaliar um sistema de classificação de imagens para identificar personagens da série 'Os Simpsons', conforme as especificações do trabalho da disciplina de Inteligência Computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importação das Bibliotecas\n",
    "\n",
    "Nesta seção, importamos todas as bibliotecas necessárias para o desenvolvimento do trabalho, incluindo manipulação de arquivos, processamento de imagens, machine learning e visualização de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skimage.feature import local_binary_pattern\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregamento e Pré-processamento dos Dados\n",
    "\n",
    "Aqui, definimos as funções para carregar as imagens dos diretórios de treino e validação. As imagens são redimensionadas para um tamanho padrão (64x64 pixels) para garantir consistência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for character_folder in os.listdir(folder):\n",
    "        char_path = os.path.join(folder, character_folder)\n",
    "        if os.path.isdir(char_path):\n",
    "            for filename in os.listdir(char_path):\n",
    "                img_path = os.path.join(char_path, filename)\n",
    "                try:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # Carrega em escala de cinza\n",
    "                    if img is not None:\n",
    "                        img = cv2.resize(img, (64, 64)) # Redimensiona\n",
    "                        images.append(img)\n",
    "                        labels.append(character_folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Caminhos para os dados\n",
    "train_folder = 'imgs/Train'\n",
    "valid_folder = 'imgs/Valid'\n",
    "\n",
    "# Carregar imagens de treino e validação\n",
    "X_train_img, y_train_str = load_images_from_folder(train_folder)\n",
    "X_valid_img, y_valid_str = load_images_from_folder(valid_folder)\n",
    "\n",
    "# Codificar os rótulos (labels) para formato numérico\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train_str)\n",
    "y_valid = label_encoder.transform(y_valid_str)\n",
    "\n",
    "print(f\"Imagens de treino carregadas: {len(X_train_img)}\")\n",
    "print(f\"Rótulos de treino carregados: {len(y_train)}\")\n",
    "print(f\"Imagens de validação carregadas: {len(X_valid_img)}\")\n",
    "print(f\"Rótulos de validação carregados: {len(y_valid)}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extração de Características\n",
    "\n",
    "Para que os algoritmos de classificação possam processar as imagens, precisamos extrair vetores de características delas. Implementamos duas abordagens:\n",
    "1. **Flattening:** Um método simples que transforma a matriz de pixels 2D da imagem em um vetor 1D.\n",
    "2. **Local Binary Patterns (LBP):** Um descritor de textura mais robusto que captura padrões locais na imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, method='flatten'):\n",
    "    if method == 'flatten':\n",
    "        # Simplesmente achata a imagem\n",
    "        return images.reshape(len(images), -1)\n",
    "    \n",
    "    elif method == 'lbp':\n",
    "        # Extrai características LBP\n",
    "        features = []\n",
    "        radius = 1\n",
    "        n_points = 8 * radius\n",
    "        for img in images:\n",
    "            lbp = local_binary_pattern(img, n_points, radius, method='uniform')\n",
    "            (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-6) # Normaliza\n",
    "            features.append(hist)\n",
    "        return np.array(features)\n",
    "    else:\n",
    "        raise ValueError(\"Método de extração de características desconhecido\")\n",
    "\n",
    "# Extrair características (usando LBP como exemplo)\n",
    "print(\"Extraindo características LBP...\")\n",
    "X_train_features = extract_features(X_train_img, method='lbp')\n",
    "X_valid_features = extract_features(X_valid_img, method='lbp')\n",
    "\n",
    "# Normalizar os dados de características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "X_valid_scaled = scaler.transform(X_valid_features)\n",
    "\n",
    "print(f\"Dimensão do vetor de características de treino: {X_train_scaled.shape}\")\n",
    "print(f\"Dimensão do vetor de características de validação: {X_valid_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Treinamento, Otimização de Hiperparâmetros e Avaliação\n",
    "\n",
    "Nesta seção, treinamos e avaliamos os classificadores solicitados: k-NN, Árvore de Decisão, SVM e MLP.\n",
    "\n",
    "Para cada classificador, realizamos os seguintes passos:\n",
    "1. **Definição do Espaço de Hiperparâmetros:** Criamos um dicionário com os hiperparâmetros a serem testados.\n",
    "2. **Otimização com GridSearchCV:** Usamos validação cruzada (k=5) para encontrar a melhor combinação de hiperparâmetros.\n",
    "3. **Treinamento do Modelo Final:** Treinamos o classificador com os melhores hiperparâmetros encontrados em todo o conjunto de treino.\n",
    "4. **Avaliação no Conjunto de Validação:** Fazemos previsões no conjunto de validação e calculamos as métricas de desempenho (Acurácia, Precisão, Recall, F1-Score) e a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, param_grid, X_train, y_train, X_valid, y_valid, model_name):\n",
    "    print(f\"--- Otimizando e Avaliando {model_name} ---\")\n",
    "    \n",
    "    # Configura o GridSearchCV com validação cruzada (k=5)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    # Executa a busca pelos melhores hiperparâmetros\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Melhores parâmetros: {grid_search.best_params_}\")\n",
    "    print(f\"Melhor acurácia (validação cruzada): {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Treina o modelo final com os melhores parâmetros\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Faz previsões no conjunto de validação\n",
    "    y_pred = best_model.predict(X_valid)\n",
    "    \n",
    "    # Calcula e exibe as métricas de avaliação\n",
    "    print(\"\n",
    "Relatório de Classificação no Conjunto de Validação:\")\n",
    "    print(classification_report(y_valid, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Calcula e exibe a matriz de confusão\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.title(f'Matriz de Confusão - {model_name}')\n",
    "    plt.xlabel('Rótulo Previsto')\n",
    "    plt.ylabel('Rótulo Verdadeiro')\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_model = train_and_evaluate_model(KNeighborsClassifier(), knn_params, X_train_scaled, y_train, X_valid_scaled, y_valid, 'k-NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "tree_model = train_and_evaluate_model(DecisionTreeClassifier(random_state=42), tree_params, X_train_scaled, y_train, X_valid_scaled, y_valid, 'Árvore de Decisão')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "svm_model = train_and_evaluate_model(SVC(random_state=42, probability=True), svm_params, X_train_scaled, y_train, X_valid_scaled, y_valid, 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. Multi-layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp_model = train_and_evaluate_model(MLPClassifier(random_state=42, max_iter=500), mlp_params, X_train_scaled, y_train, X_valid_scaled, y_valid, 'MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusão\n",
    "\n",
    "Neste notebook, implementamos um fluxo completo de trabalho de machine learning para classificação de personagens dos Simpsons. Carregamos e pré-processamos os dados, extraímos características usando LBP, e otimizamos e avaliamos quatro classificadores diferentes usando validação cruzada e `GridSearchCV`.\n",
    "\n",
    "Os resultados, incluindo as métricas de desempenho e as matrizes de confusão para cada modelo no conjunto de validação, foram apresentados. Esta análise permite comparar a eficácia de cada classificador para esta tarefa específica e identificar seus pontos fortes e fracos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
